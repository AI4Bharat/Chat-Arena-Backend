"""
Sentence generation pipeline.
Ported from synthetic-benchmarks/models/sentence_generator/engine.py
Generates sentences using Gemini API based on configuration.
"""

import os
import json
from typing import List, Dict, Tuple
from ..entities import Config
from ..utils import save_jsonl_file, load_jsonl_file, http_utils


def generate_sentence_pipeline(config: Config) -> Tuple[List[Dict], str]:
    """
    Generate sentences for the dataset using Gemini API
    
    Args:
        config: Dataset configuration
        
    Returns:
        Tuple of (sentences list, error message)
    """
    try:
        if not config:
            return [], "Config is null"
        
        if not config.sentence_config:
            return [], "Sentence config is missing"
        
        # Generate sentences using Gemini
        sentences, err = _generate_sentences_with_gemini(config)
        if err:
            return [], f"Error generating sentences: {err}"
        
        if not sentences:
            return [], "No sentences were generated by Gemini API"
        
        # Save sentences to file
        job_id = config.job_id
        sentences_file = _get_sentences_file_path(job_id)
        
        sentences_with_meta = [
            {'id': idx, 'sentence': sent} 
            for idx, sent in enumerate(sentences)
        ]
        
        err = save_jsonl_file(sentences_with_meta, sentences_file)
        if err:
            return [], f"Failed to save sentences: {err}"
        
        return sentences_with_meta, ""
        
    except Exception as e:
        return [], f"Exception in sentence generation: {str(e)}"


def _generate_sentences_with_gemini(config: Config) -> Tuple[List[str], str]:
    """
    Call Gemini API to generate sentences
    
    Args:
        config: Dataset configuration
        
    Returns:
        Tuple of (sentences list, error message)
    """
    try:
        api_key = os.getenv('GEMINI_API_KEY')
        if not api_key:
            return [], "GEMINI_API_KEY environment variable not set"
        
        prompt = _build_sentence_prompt(config)
        
        headers = {
            'x-goog-api-key': api_key,
            'Content-Type': 'application/json'
        }
        
        body = {
            'contents': [{
                'parts': [{'text': prompt}]
            }],
            'generationConfig': {
                'seed': 500,  # Fixed seed for reproducibility
                'responseMimeType': 'application/json',
                'responseJsonSchema': {
                    'type': 'object',
                    'properties': {
                        'sentences': {
                            'type': 'array',
                            'items': {'type': 'string'}
                        }
                    },
                    'required': ['sentences']
                }
            }
        }
        
        result, err = http_utils.make_post_request(
            'generativelanguage.googleapis.com',
            '/v1beta/models/gemini-2.5-flash:generateContent',
            headers,
            body
        )
        
        if err:
            return [], f"Gemini API error: {err}"
        
        # Parse response
        sentences = []
        if isinstance(result, dict):
            candidates = result.get('candidates', [])
            for candidate in candidates:
                content = candidate.get('content', {})
                parts = content.get('parts', [])
                for part in parts:
                    text = part.get('text', '')
                    if text:
                        try:
                            data = json.loads(text)
                            sentences.extend(data.get('sentences', []))
                        except json.JSONDecodeError:
                            pass
        
        return sentences, ""
        
    except Exception as e:
        return [], f"Exception calling Gemini API: {str(e)}"


def _build_sentence_prompt(config: Config) -> str:
    """
    Build detailed prompt for Gemini to generate sentences
    
    Args:
        config: Dataset configuration
        
    Returns:
        Prompt string
    """
    sentence_config = config.sentence_config
    
    prompt = f"""
You are an expert text generator for ASR (Automatic Speech Recognition) training data. 
Generate diverse, natural sentences in {config.language} for training an ASR model.

Dataset Requirements:
- Domain/Category: {sentence_config.category}
- Language: {config.language}
- Sentence Styles: {', '.join(sentence_config.style)}
- Target Duration: {config.size} hours of audio
- Description: {sentence_config.description or 'No specific description'}
- Related Entities: {', '.join(sentence_config.entities) if sentence_config.entities else 'None'}

Generation Guidelines:
{f"- Topics/Personas: {sentence_config.topic_persona_instruction}" if sentence_config.topic_persona_instruction else ""}
{f"- Sub-domain Focus: {sentence_config.sub_domain_instruction}" if sentence_config.sub_domain_instruction else ""}
{f"- Scenarios: {sentence_config.scenario_instruction}" if sentence_config.scenario_instruction else ""}

Important Rules:
- Generate sentences that are natural and realistic for the given domain
- Vary sentence length and complexity
- Include the specified entities where relevant
- Follow the sentence styles specified
- Ensure linguistic diversity
- DO NOT include explanations or commentary
- Return ONLY valid JSON

Generate 50 sentences suitable for ASR training.
"""
    
    return prompt


def _get_sentences_file_path(job_id: str) -> str:
    """
    Get path where sentences should be saved
    
    Args:
        job_id: Job ID
        
    Returns:
        File path
    """
    parent_folder = os.getenv('SYNTHETIC_ASR_DATA_PATH', '/tmp/synthetic_asr')
    return f"{parent_folder}/{job_id}/sentences.jsonl"
