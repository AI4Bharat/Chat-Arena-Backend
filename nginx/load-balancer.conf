# Load Balancer Configuration for Arena Backend
# This file defines upstream servers and load balancing policies

# Upstream group for Django backend servers
upstream django_backend {
    # Load balancing algorithm: Round Robin (default)
    # Distributes requests evenly across all servers
    # Alternative algorithms:
    # - least_conn: Routes to server with fewest active connections (better for streaming)
    # - ip_hash: Routes based on client IP (sticky sessions)
    # - hash $request_uri: Routes based on requested URI

    # Connection settings
    # keepalive: Number of idle keepalive connections to upstream servers
    # This significantly reduces overhead by reusing TCP connections
    keepalive 64;
    keepalive_timeout 60s;
    keepalive_requests 100;

    # Upstream server definitions
    # Each server runs a Django instance via Gunicorn on port 8000
    #
    # Parameters explained:
    # - max_fails=3: Mark server as down after 3 failed attempts
    # - fail_timeout=30s: Time to wait before retrying a failed server
    # - max_conns=200: Maximum concurrent connections per server (prevents overload)
    # - weight=1: Load distribution weight (higher = more traffic)

    server web-1:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-2:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-3:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-4:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-5:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-6:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-7:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-8:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-9:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
    server web-10:8000 max_fails=3 fail_timeout=30s max_conns=200 weight=1;
}

# Upstream group specifically for streaming endpoints (SSE)
# Uses least_conn for better distribution of long-lived connections
upstream django_streaming {
    least_conn;  # Route to server with fewest active connections

    keepalive 32;
    keepalive_timeout 120s;  # Longer timeout for streaming

    server web-1:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-2:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-3:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-4:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-5:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-6:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-7:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-8:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-9:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
    server web-10:8000 max_fails=2 fail_timeout=60s max_conns=100 weight=1;
}

# Upstream group for WebSocket connections with sticky sessions
# Uses IP hash to ensure WebSocket connections from same client go to same backend
# This is useful for stateful WebSocket operations
upstream django_websocket {
    # IP hash for sticky sessions - same client IP always routes to same backend
    # This ensures WebSocket reconnections go to the same server
    ip_hash;

    keepalive 32;
    keepalive_timeout 300s;  # Long timeout for persistent WebSocket connections

    server web-1:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-2:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-3:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-4:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-5:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-6:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-7:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-8:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-9:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
    server web-10:8000 max_fails=2 fail_timeout=60s max_conns=150 weight=1;
}

# Nginx event and worker configuration
# Increase these values to handle high concurrency
# These go in the main nginx.conf, but documented here for reference:
#
# events {
#     worker_connections 10000;  # Concurrent connections per worker
#     use epoll;  # Efficient connection processing on Linux
#     multi_accept on;  # Accept multiple connections at once
# }
#
# worker_processes auto;  # One worker per CPU core
# worker_rlimit_nofile 20000;  # Maximum open file descriptors

# Rate limiting zones
# Protects against DDoS and ensures fair resource allocation
limit_req_zone $binary_remote_addr zone=general_limit:10m rate=100r/s;
limit_req_zone $binary_remote_addr zone=streaming_limit:10m rate=10r/s;
limit_req_zone $binary_remote_addr zone=auth_limit:10m rate=5r/s;

# Connection limit zone
# Limits concurrent connections per IP
limit_conn_zone $binary_remote_addr zone=conn_limit:10m;

# Proxy cache configuration (for static responses)
proxy_cache_path /var/cache/nginx levels=1:2 keys_zone=api_cache:10m max_size=1g inactive=60m use_temp_path=off;

# Logging format with load balancer details
log_format load_balanced '$remote_addr - $remote_user [$time_local] '
                        '"$request" $status $body_bytes_sent '
                        '"$http_referer" "$http_user_agent" '
                        'upstream: $upstream_addr '
                        'upstream_status: $upstream_status '
                        'upstream_response_time: $upstream_response_time '
                        'request_time: $request_time';
